{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pIqf7OkPMOki"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vYGJLWZxMOkj"
      },
      "outputs": [],
      "source": [
        "# Loading dataset\n",
        "# path_df = r'C:\\Users\\91951\\Downloads\\dataset.csv'\n",
        "df = pd.read_csv('dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "SYv-GUHf7G6Q",
        "outputId": "392b5672-5b9b-4713-9ee7-16ea95a8dfaf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "sns.heatmap(df.corr())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muJ2gq5uMOkj",
        "outputId": "5feff9dd-86c9-4f4f-9e55-6bccb7d7907c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "f1        0\n",
              "f2        0\n",
              "f3        0\n",
              "f4        0\n",
              "f5        0\n",
              "f6        0\n",
              "f7        0\n",
              "target    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()  # No empty cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U26xBvlRMOkj",
        "outputId": "7c36015e-df30-4e7b-e10b-59512fbee945"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()  # No duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjozJqOZMOkj",
        "outputId": "eda1ba1d-f76f-45fa-d11b-b3046cd175ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 766 entries, 0 to 765\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   f1      766 non-null    object\n",
            " 1   f2      766 non-null    object\n",
            " 2   f3      766 non-null    int64 \n",
            " 3   f4      766 non-null    object\n",
            " 4   f5      766 non-null    object\n",
            " 5   f6      766 non-null    object\n",
            " 6   f7      766 non-null    object\n",
            " 7   target  766 non-null    int64 \n",
            "dtypes: int64(2), object(6)\n",
            "memory usage: 48.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n3Zy2wsMOkj",
        "outputId": "2412709b-567e-4b6a-9bda-1242e3a46a30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "f1        1\n",
              "f2        1\n",
              "f3        0\n",
              "f4        1\n",
              "f5        1\n",
              "f6        1\n",
              "f7        1\n",
              "target    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.apply(lambda x: pd.to_numeric(x, errors='coerce')).isna().sum()  #we can drop Na values or just replace them with mean of the column data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D1eeFaPNMOkk"
      },
      "outputs": [],
      "source": [
        "df = df.apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna()  #3 rows dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5VpoFCZMOkk"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler  # useless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wEvQMMBbMOkk"
      },
      "outputs": [],
      "source": [
        "X = df.drop('target', axis=1).values\n",
        "y = df.target\n",
        "# print(X.dtypes)\n",
        "# print(y.dtypes)\n",
        "\n",
        "# Scale numerical features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# print(type(X_train),type(X_test),type(y_train),type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "jgmL12MW6-Sc",
        "outputId": "3afa5fda-9de9-4219-9eaf-b475314c719a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGiCAYAAAB6c8WBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzEElEQVR4nO3de1xVdb7/8fcGZZOKUCiIt9C8jzeU8qCpWZrWHNO0Mm3UsGFmTEeUsYxM0ZpEu/jTGW9hSXbKtNNkjy4OZk7WyUsiamrjJQRixgN4K0zTjbHX7w9PzOwN5t66YAHr9eyxHo/87rXX+ixK9md/Pt/vWg7DMAwBAADbCrA6AAAAYC2SAQAAbI5kAAAAmyMZAADA5kgGAACwOZIBAABsjmQAAACbIxkAAMDmSAYAALA5kgEAAGyOZAAAgGris88+09ChQ9W0aVM5HA69++67V3zPli1b1KNHDzmdTrVp00avvvqq3+clGQAAoJo4d+6cunXrpqVLl/q0f25urn75y19qwIAB2rt3r6ZOnapf//rX2rhxo1/ndfCgIgAAqh+Hw6H169dr+PDhl91nxowZ+vDDD3XgwIGysQcffFDfffedMjIyfD4XlQEAACqRy+XSmTNnPDaXy2XKsbdv366BAwd6jA0ePFjbt2/36zh1TInGBBdP5lgdwjW7t8fvrQ7BFHVrSY74fuFuq0O4ZgEOh9UhmOLGhpFWh3DNvis5a3UIpvjV9TFWh2CK/5e3tlKPb+ZnUuqS1zR37lyPsZSUFM2ZM+eaj11YWKjISM+/X5GRkTpz5ozOnz+v6667zqfjVJtkAACAasNdatqhkpOTlZSU5DHmdDpNO74ZSAYAAKhETqez0j78mzRpoqKiIo+xoqIiNWzY0OeqgEQyAABAeYbb6gh8EhcXpw0bNniMbdq0SXFxcX4dp3Y0hwEAMJPbbd7mh7Nnz2rv3r3au3evpEtLB/fu3av8/HxJl1oO48aNK9v/d7/7nXJycvT444/r0KFDWrZsmd566y1NmzbNr/NSGQAAwIthUWVg165dGjBgQNmff5prMH78eL366qsqKCgoSwwkqVWrVvrwww81bdo0LV68WM2bN9fLL7+swYMH+3VekgEAAKqJ2267TT93+5+K7i542223ac+ePdd0XpIBAAC8+Vner+lIBgAA8FZDJhCahQmEAADYHJUBAAC8mXjToZqAZAAAAG+0CQAAgJ1QGQAAwBurCQAAsDerbjpkFdoEAADYHJUBAAC80SYAAMDmbNYmIBkAAMCbze4zwJwBAABszrRk4B//+IcmTJhg1uEAALCO4TZvqwFMSwZOnz6t1atXm3U4AACs43abt9UAPs8ZeO+993729ZycHJ9P6nK55HK5PMYCXC45nU6fjwEAAMzhczIwfPhwORwOGYZx2X0cDodPx0pNTdXcuXM9xp56bIpmP57oazgAAFSeGlLeN4vPbYKoqCi98847crvdFW67d+/2+aTJyckqLi722GYk/u6qLgAAANPZrE3gczLQs2dPZWVlXfb1K1UN/p3T6VTDhg09NloEAABYw6c2wb59+/TYY4/p3Llzl92nTZs2+uSTT0wLDAAAqxiGve4z4FMyEBMTo4KCAkVERKh169bKzMxUeHi4xz7169dX//79KyVIAACqFHMGygsLC1Nubq4kKS8vT+4a0gMBAABX5lNlYOTIkerfv7+ioqLkcDgUGxurwMDACvf1Z4khAADVks2+9PqUDKSlpWnEiBHKzs7WlClTlJCQoJCQkMqODQAAa9isTeDzfQaGDBkiScrKylJiYiLJAACg9rLZg4r8fmphenp6ZcQBAAAswiOMAQDwRpsAAACbs9kEQtOeWggAAGomKgMAAHijTQAAgM3RJgAAAHZCZQAAAG82qwyQDAAA4MVuTy2kTQAAgM1RGQAAwBttAgAAbI6lhQAA2JzNKgPMGQAAwOaqTWXg3h6/tzqEa7Z+95+tDsEUY3pOszoEU3QNb2V1CNdsYmC01SGYYn+di1aHcM2+ue6c1SGYYmzpeatDqBloEwAAYHO0CQAAgJ1QGQAAwBttAgAAbI42AQAAsBMqAwAAeLNZZYBkAAAAbzabM0CbAAAAm6MyAACAN9oEAADYnM3aBCQDAAB4s1llgDkDAADYHJUBAAC80SYAAMDmaBMAAAA7oTIAAIA3m1UGSAYAAPBmGFZHUKVoEwAAUI0sXbpU0dHRCg4OVq9evbRz586f3X/RokVq3769rrvuOrVo0ULTpk3ThQsX/DonlQEAALxZ1CZYt26dkpKStGLFCvXq1UuLFi3S4MGDdfjwYUVERJTbf82aNXriiSe0atUq9e7dW0eOHNHDDz8sh8OhhQsX+nxevyoD58+f1+eff66///3v5V67cOGCXnvtNX8OBwBA9eR2m7f5YeHChUpISFB8fLw6deqkFStWqF69elq1alWF+2/btk19+vTRmDFjFB0drTvvvFOjR4++YjXBm8/JwJEjR9SxY0f169dPXbp0Uf/+/VVQUFD2enFxseLj4/06OQAAtZ3L5dKZM2c8NpfLVW6/kpISZWVlaeDAgWVjAQEBGjhwoLZv317hsXv37q2srKyyD/+cnBxt2LBBd999t18x+pwMzJgxQ507d9bx48d1+PBhhYSEqE+fPsrPz/frhFLFP5hSo9Tv4wAAUCkMt2lbamqqQkNDPbbU1NRypzx58qRKS0sVGRnpMR4ZGanCwsIKwxwzZoyefvpp3Xrrrapbt65uuukm3XbbbXryySf9ulyfk4Ft27YpNTVVjRo1Ups2bfT+++9r8ODB6tu3r3Jycvw6aUU/mKNnjvp1DAAAKo2JbYLk5GQVFxd7bMnJyaaEuWXLFs2bN0/Lli3T7t279c477+jDDz/UM88849dxfE4Gzp8/rzp1/jXf0OFwaPny5Ro6dKj69++vI0eO+HzSin4wNzW8ya/AAQCoNIZh2uZ0OtWwYUOPzel0ljtlo0aNFBgYqKKiIo/xoqIiNWnSpMIwZ82apbFjx+rXv/61unTponvvvVfz5s1Tamqq3H7MV/A5GejQoYN27dpVbnzJkiUaNmyY7rnnHp9PWtEPJtAR6PP7AQCobYKCgtSzZ09t3ry5bMztdmvz5s2Ki4ur8D0//PCDAgI8P8oDAy99nhp+3CvBp2Rg3759uueee/Tmm29W+PqSJUs0evRov04MAEC1ZdFqgqSkJK1cuVKrV6/WwYMHNXHiRJ07d65sgv64ceM8WgxDhw7V8uXLtXbtWuXm5mrTpk2aNWuWhg4dWpYU+MKn+wzExMSooKBATz31lFq3bq3MzEyFh4d77LNs2TItW7bM5xMDAFBtWXSfgVGjRunEiROaPXu2CgsL1b17d2VkZJRNKszPz/eoBDz11FNyOBx66qmndOzYMTVu3FhDhw7Vs88+69d5fUoGwsLClJubq4iICOXl5fnVhwAAAL6bPHmyJk+eXOFrW7Zs8fhznTp1lJKSopSUlGs6p0/JwMiRI9WvXz81bdpUDodDsbGxly0/+LuyAACAasew15den5KBtLQ0jRgxQtnZ2ZoyZYoSEhIUEhJS2bEBAGAJw22vOXA+P5tgyJAhkqSsrCwlJiaSDAAAUEv4/aCi9PT0yogDAIDqw2Zz43hqIQAA3mw2Z8CvpxYCAIDah8oAAADemEAIAIDNMWcAAACbs1kywJwBAABsjsoAAADebPbgPZIBAAC80SYAAAB2QmUAAABvLC0EAMDmuAMhAACwEyoDAAB4o01gjbq1oEgxpuc0q0MwxZqs/2d1CKaYEvuE1SFcs9cuFlgdginuNqKsDuGabSk5ZXUIpvhtQF2rQzBFZiUf32A1AQAAsJNqUxkAAKDaoE0AAIDN2Ww1AckAAADebFYZYM4AAAA2R2UAAABvNltNQDIAAIA32gQAAMBOqAwAAOCN1QQAANgcbQIAAGAnVAYAAPBit2cTkAwAAOCNNgEAALATKgMAAHizWWWAZAAAAG8sLQQAwOZsVhlgzgAAADZHZQAAAC8GlYHLO3jwoNLT03Xo0CFJ0qFDhzRx4kRNmDBBf/vb3yolQAAAqpzbMG+rAXyuDGRkZGjYsGFq0KCBfvjhB61fv17jxo1Tt27d5Ha7deedd+qjjz7S7bffXpnxAgAAk/lcGXj66af12GOP6dSpU0pPT9eYMWOUkJCgTZs2afPmzXrsscc0f/58n47lcrl05swZj63UKL3qiwAAwFRut3lbDeBzMvDVV1/p4YcfliQ98MAD+v7773XfffeVvf7QQw9p3759Ph0rNTVVoaGhHtuRM9n+RQ4AQGWxWZvArzkDDofj0psCAhQcHKzQ0NCy10JCQlRcXOzTcZKTk1VcXOyxtWvYxp9QAACASXyeMxAdHa2vv/5aN910kyRp+/btatmyZdnr+fn5ioqK8ulYTqdTTqfTYyzQEehrKAAAVK4a8o3eLD4lA/v27VNCQoJKS//V1+/cubPHPn/961+ZPAgAqBUMg2SgnJiYGBUUFCgiIkKtW7dWZmamwsPDPfaZN29epQQIAAAql09zBsLCwpSbmytJysvLk7uGzI4EAOCq2GwCoU+VgZEjR6pfv35q2rSpHA6HYmNjFRhYcY8/JyfH1AABAKhyNeRD3Cw+JQNpaWkaMWKEsrOzNWXKFCUkJCgkJKSyYwMAwBJ2ux2xz6sJhgwZIknKyspSYmIiyQAAALWE3w8qSk9Pr4w4AACoPqgMAABgczabJ+/XHQgBAEDtQ2UAAAAvTCAEAMDubJYM0CYAAMDmqAwAAODNZhMISQYAAPBitzkDtAkAAKhGli5dqujoaAUHB6tXr17auXPnz+7/3XffadKkSYqKipLT6VS7du20YcMGv85JZQAAAG8WtQnWrVunpKQkrVixQr169dKiRYs0ePBgHT58WBEREeX2Lykp0aBBgxQREaG3335bzZo10zfffKOwsDC/zksyAACAF6vaBAsXLlRCQoLi4+MlSStWrNCHH36oVatW6Yknnii3/6pVq3T69Glt27ZNdevWlSRFR0f7fV7aBAAAeHObt7lcLp05c8Zjc7lc5U5ZUlKirKwsDRw4sGwsICBAAwcO1Pbt2ysM87333lNcXJwmTZqkyMhIde7cWfPmzVNpaalfl0syAABAJUpNTVVoaKjHlpqaWm6/kydPqrS0VJGRkR7jkZGRKiwsrPDYOTk5evvtt1VaWqoNGzZo1qxZevHFF/XHP/7RrxhpEwAA4MUwcc5AcnKykpKSPMacTqcpx3a73YqIiFBaWpoCAwPVs2dPHTt2TM8//7xSUlJ8Pk61SQbeL9xtdQjXrGt4K6tDMMWU2PJ9qZroT7vmWx3CNdvZ+XGrQzDFaT9LltVRz+CmVodgikMXT1sdQs1gYjLgdDp9+vBv1KiRAgMDVVRU5DFeVFSkJk2aVPieqKgo1a1bV4GBgWVjHTt2VGFhoUpKShQUFORTjLQJAACoBoKCgtSzZ09t3ry5bMztdmvz5s2Ki4ur8D19+vRRdna23O5/ZS9HjhxRVFSUz4mARDIAAEA5htu8zR9JSUlauXKlVq9erYMHD2rixIk6d+5c2eqCcePGKTk5uWz/iRMn6vTp00pMTNSRI0f04Ycfat68eZo0aZJf5602bQIAAKoNi+4zMGrUKJ04cUKzZ89WYWGhunfvroyMjLJJhfn5+QoI+Nf3+BYtWmjjxo2aNm2aunbtqmbNmikxMVEzZszw67wkAwAAVCOTJ0/W5MmTK3xty5Yt5cbi4uK0Y8eOazonyQAAAF7MXE1QE5AMAADghWQAAACbs1sywGoCAABsjsoAAADeDIfVEVQpkgEAALzQJgAAALZCZQAAAC+GmzYBAAC2RpsAAADYCpUBAAC8GKwmAADA3mgTAAAAW6EyAACAF1YT+MkwDDkc9vqhAQBqN8OwOoKqdc1tAqfTqYMHD5oRCwAA1YLhdpi21QQ+VwaSkpIqHC8tLdX8+fMVHh4uSVq4cKE5kQEAgCrhczKwaNEidevWTWFhYR7jhmHo4MGDql+/vs/tApfLJZfLVe44tBsAANVBTflGbxafk4F58+YpLS1NL774om6//fay8bp16+rVV19Vp06dfD5pamqq5s6d6zHmCGggR2BDn48BAEBlYc7AZTzxxBNat26dJk6cqOnTp+vixYtXfdLk5GQVFxd7bI6AkKs+HgAAuHp+TSC8+eablZWVpRMnTig2NlYHDhy4qtK+0+lUw4YNPTZaBACA6oIJhBXYt2+fOnfurICAADVo0ECrV6/W2rVrNXDgQJWWllZ2jAAAVCm73Y7Yp8pATEyMTp48KUlq3bq1Tp06pQcffFCZmZl655131LJly0oNEgAAVB6fKgNhYWHKzc1VRESE8vLy5HZfumlzixYt1KJFi0oNEACAqma3ZxP4lAyMHDlS/fv3V1RUlBwOh2JjYxUYGFjhvjk5OaYGCABAVXPbrE3gUzKQlpamESNGKDs7W1OmTFFCQoJCQpj9DwBAbeDzfQaGDBkiScrKylJiYiLJAACg1rLbBEK/H1SUnp5eGXEAAFBt1JQlgWbhEcYAAHjhDoQAAMBWqAwAAOCFNgEAADZnt6WFtAkAALA5KgMAAHhhaSEAADbHagIAAGArVAYAAPBitwmEJAMAAHix25wB2gQAANgclQEAALzYbQIhyQAAAF6YM2CRAEfN/8FPDIy2OgRTvHaxwOoQTLGz8+NWh3DNbjnwnNUhmGJy7AyrQ8D/aRRY3+oQagTmDAAAAFupNpUBAACqC9oEAADYnM3mD9ImAADA7qgMAADghTYBAAA2x2oCAABgK1QGAADw4rY6gCpGMgAAgBdDtAkAAICNUBkAAMCL22Y3GiAZAADAi9tmbQKSAQAAvDBnAAAA2AqVAQAAvNhtaSGVAQAAvBhymLb5a+nSpYqOjlZwcLB69eqlnTt3+vS+tWvXyuFwaPjw4X6fk2QAAIBqYt26dUpKSlJKSop2796tbt26afDgwTp+/PjPvi8vL0/Tp09X3759r+q8JAMAAHhxm7j5Y+HChUpISFB8fLw6deqkFStWqF69elq1atVl31NaWqqHHnpIc+fOVevWrf084yUkAwAAeDEzGXC5XDpz5ozH5nK5yp2zpKREWVlZGjhwYNlYQECABg4cqO3bt1821qeffloRERF65JFHrvp6rzoZOHfunNLT0zVz5kwtWbJEp06duuogAACorVJTUxUaGuqxpaamltvv5MmTKi0tVWRkpMd4ZGSkCgsLKzz2559/rldeeUUrV668phh9Xk3QqVMnff7557rhhhv0j3/8Q/369dO3336rdu3a6ejRo3rmmWe0Y8cOtWrV6poCAgDAambeZyA5OVlJSUkeY06n85qP+/3332vs2LFauXKlGjVqdE3H8jkZOHTokH788UdJly6sadOm2rt3r0JDQ3X27Fnde++9mjlzptasWXNNAQEAYDW3ifcccjqdPn34N2rUSIGBgSoqKvIYLyoqUpMmTcrtf/ToUeXl5Wno0KFlY273pVkKderU0eHDh3XTTTf5FONVtQm2b9+uOXPmKDQ0VJLUoEEDzZ07V59//rlP76+of2IYNrsRNAAA/yYoKEg9e/bU5s2by8bcbrc2b96suLi4cvt36NBB+/fv1969e8u2e+65RwMGDNDevXvVokULn8/t102HHI5LqdKFCxcUFRXl8VqzZs104sQJn46TmpqquXPneowFBIQosE5Df8IBAKBSWPVsgqSkJI0fP16xsbG65ZZbtGjRIp07d07x8fGSpHHjxqlZs2ZKTU1VcHCwOnfu7PH+sLAwSSo3fiV+JQN33HGH6tSpozNnzujw4cMeJ/vmm28UHh7u03Eq6p+EN+roTygAAFQaq2rVo0aN0okTJzR79mwVFhaqe/fuysjIKJtUmJ+fr4AA8xcC+pQM7Nu3TzNnzlSdOv/avUGDBh77vP/++z7f7KCi/slPVQcAAKxm5e2IJ0+erMmTJ1f42pYtW372va+++upVndOnZCAmJkYFBQWKiIhQ69atlZmZWa4K8Pzzz19VAAAAwFo+JQNhYWHKzc1VRESE8vLyymYrAgBQG7ltVq32KRkYOXKk+vXrp6ZNm8rhcCg2NlaBgYEV7puTk2NqgAAAVDW7rW/zKRlIS0vTiBEjlJ2drSlTpighIUEhISGVHRsAAKgCPq8mGDJkiCQpKytLiYmJJAMAgFrLbs1wv5YWSlJ6enplxAEAQLVh5h0IawKeWggAgM35XRkAAKC2s+oOhFYhGQAAwIvdVhPQJgAAwOaoDAAA4MVuEwhJBgAA8MLSQgAAbI45AwAAwFaoDAAA4IU5AwAA2Jzd5gzQJgAAwOaoDAAA4MVulQGSAQAAvBg2mzNAmwAAAJurNpWBGxtGWh3CNdtf56LVIZjibiPK6hBMcbq01OoQrtnk2BlWh2CKJbsWWB3CNXugR6LVIZiiryPM6hBqBNoEAADYnN2SAdoEAADYHJUBAAC82O12xCQDAAB44Q6EAADYHHMGAACArVAZAADAi90qAyQDAAB4sdsEQtoEAADYHJUBAAC8sJoAAACbs9ucAdoEAADYHJUBAAC82G0CIckAAABe3DZLB2gTAABgc1QGAADwYrcJhCQDAAB4sVeTgGQAAIBy7FYZYM4AAAA253MysHv3buXm5pb9+b/+67/Up08ftWjRQrfeeqvWrl1bKQECAFDV3A7ztprA52QgPj5eR48elSS9/PLL+u1vf6vY2FjNnDlTN998sxISErRq1apKCxQAgKrilmHaVhP4PGfg66+/Vtu2bSVJy5Yt0+LFi5WQkFD2+s0336xnn31WEyZMuOKxXC6XXC6Xx5hhuOVw0LUAAKCq+fzpW69ePZ08eVKSdOzYMd1yyy0er/fq1cujjfBzUlNTFRoa6rGd/qHQj7ABAKg8holbTeBzMnDXXXdp+fLlkqT+/fvr7bff9nj9rbfeUps2bXw6VnJysoqLiz22G+o18SNsAAAqj9vErSbwuU2wYMEC9enTR/3791dsbKxefPFFbdmyRR07dtThw4e1Y8cOrV+/3qdjOZ1OOZ1OjzFaBAAAWMOnT+B9+/apSZMm2rNnj3r37q2MjAwZhqGdO3fqo48+UvPmzbV161bdfffdlR0vAACVjgmEFYiJiVFBQYEiIiK0bt06ZWZmKjw8vLJjAwDAEjXjI9w8PlUGwsLCyiYH5uXlye2uKV0QAABwJT5VBkaOHKn+/fsrKipKDodDsbGxCgwMrHDfnJwcUwMEAKCq2e0rr0/JQFpamkaMGKHs7GxNmTJFCQkJCgkJqezYAACwRE3p9ZvF59UEQ4YMkSRlZWUpMTGRZAAAUGvZKxW4iqcWpqenV0YcAADAIjzCGAAAL8wZAADA5gybNQq47R8AADZHZQAAAC92axNQGQAAwIuVtyNeunSpoqOjFRwcrF69emnnzp2X3XflypXq27evrr/+el1//fUaOHDgz+5/OSQDAABUE+vWrVNSUpJSUlK0e/dudevWTYMHD9bx48cr3H/Lli0aPXq0PvnkE23fvl0tWrTQnXfeqWPHjvl1XpIBAAC8GCZu/li4cKESEhIUHx+vTp06acWKFapXr55WrVpV4f5vvPGGHn30UXXv3l0dOnTQyy+/LLfbrc2bN/t1XuYMAADgxcw7ELpcLrlcLo8xp9Mpp9PpMVZSUqKsrCwlJyeXjQUEBGjgwIHavn27T+f64YcfdPHiRd1www1+xUhlAACASpSamqrQ0FCPLTU1tdx+J0+eVGlpqSIjIz3GIyMjVVhY6NO5ZsyYoaZNm2rgwIF+xUhlAAAAL2auJkhOTlZSUpLHmHdVwAzz58/X2rVrtWXLFgUHB/v1XpIBAAC8mHnToYpaAhVp1KiRAgMDVVRU5DFeVFSkJk2a/Ox7X3jhBc2fP18ff/yxunbt6neMtAkAAPDiNnHzVVBQkHr27Okx+e+nyYBxcXGXfd9zzz2nZ555RhkZGYqNjfXjjP9CZQAAgGoiKSlJ48ePV2xsrG655RYtWrRI586dU3x8vCRp3LhxatasWdmcgwULFmj27Nlas2aNoqOjy+YWNGjQQA0aNPD5vNUmGfiu5KzVIVyzb647Z3UIpthScsrqEEzRM7ip1SHg/zzQI9HqEK7ZW7sXWx2CKSb0nG51CDWCVc8mGDVqlE6cOKHZs2ersLBQ3bt3V0ZGRtmkwvz8fAUE/Kuov3z5cpWUlOi+++7zOE5KSormzJnj83mrTTIAAEB1YeXtiCdPnqzJkydX+NqWLVs8/pyXl2fKOZkzAACAzVEZAADAi9uw1yOMSQYAAPBir1SANgEAALZHZQAAAC9mPpugJiAZAADAi1VLC61CmwAAAJujMgAAgBcr7zNgBZIBAAC8MGcAAACbY84AAACwFSoDAAB4Yc4AAAA2Z9jsdsS0CQAAsDkqAwAAeGE1AQAANme3OQO0CQAAsDkqAwAAeOE+A5fx+9//Xv/zP/9TmbEAAFAtuGWYttUEPicDS5cu1W233aZ27dppwYIFKiwsrMy4AABAFfFrzsBHH32ku+++Wy+88IJatmypYcOG6YMPPpDb7d9UC5fLpTNnznhshmG36RoAgOrKMAzTtprAr2SgS5cuWrRokf73f/9Xr7/+ulwul4YPH64WLVpo5syZys7O9uk4qampCg0N9dh+cJ2+qgsAAMBsbhO3muCqVhPUrVtXDzzwgDIyMpSTk6OEhAS98cYbat++vU/vT05OVnFxscdWz3nD1YQCAIDpDBP/qQmueWlhy5YtNWfOHOXm5iojI8On9zidTjVs2NBjczhY5QgAgBV8Wlr45ZdfqlmzZgoMDLzsPg6HQ4MGDTItMAAArFJTVgGYxaev4z169FBWVpbCw8PVunVrnTp1qrLjAgDAMkwgrEBYWJhyc3MlSXl5eX6vHgAAANWXT22CkSNHql+/fmratKkcDodiY2Mv2zLIyckxNUAAAKqa3doEPiUDaWlpGjFihLKzszVlyhQlJCQoJCSksmMDAMASNWUVgFl8fjbBkCFDJElZWVlKTEwkGQAAoJbw+0FF6enplREHAADVhruGTPwzC08tBADAi71SARNuOgQAAGo2KgMAAHhhNQEAADZHMgAAgM3VlDsHmoU5AwAA2ByVAQAAvNAmAADA5ux2B0LaBAAA2ByVAQAAvNhtAiHJAAAAXuw2Z4A2AQAANkdlAAAAL7QJLPKr62OsDuGajS09b3UIpvhtQF2rQzDFoYunrQ7hmjUKrG91CKbo6wizOoRrNqHndKtDMMWqrBesDqFGoE0AAABspdpUBgAAqC7sdp8BkgEAALy4bTZnwO82QX5+foUTKwzDUH5+vilBAQBgJcPEf2oCv5OBVq1a6cSJE+XGT58+rVatWpkSFAAAqDp+twkMw5DD4Sg3fvbsWQUHB5sSFAAAVrJbm8DnZCApKUmS5HA4NGvWLNWrV6/stdLSUn3xxRfq3r276QECAFDVakp53yw+JwN79uyRdKkysH//fgUFBZW9FhQUpG7dumn69NqxDhcAADvxORn45JNPJEnx8fFavHixGjZsWGlBAQBgJbu1CfyeQJienq6GDRsqOztbGzdu1Pnzl+66Z7dbNwIAai9WE1zB6dOndccdd6hdu3a6++67VVBQIEl65JFH9Ic//MH0AAEAQOXyOxmYOnWq6tatq/z8fI9JhKNGjVJGRoapwQEAYAW3YZi21QR+JwMfffSRFixYoObNm3uMt23bVt98841pgQEAYBUr2wRLly5VdHS0goOD1atXL+3cufNn9//v//5vdejQQcHBwerSpYs2bNjg9zn9TgbOnTvnURH4yenTp+V0Ov0OAAAAXLJu3TolJSUpJSVFu3fvVrdu3TR48GAdP368wv23bdum0aNH65FHHtGePXs0fPhwDR8+XAcOHPDrvH4nA3379tVrr71W9meHwyG3263nnntOAwYM8PdwAABUO4bhNm3zx8KFC5WQkKD4+Hh16tRJK1asUL169bRq1aoK91+8eLGGDBmixx57TB07dtQzzzyjHj16aMmSJX6d1+87ED733HO64447tGvXLpWUlOjxxx/XV199pdOnT2vr1q3+Hg4AgGrHbeIqAJfLJZfL5THmdDrLVdNLSkqUlZWl5OTksrGAgAANHDhQ27dvr/DY27dvL7sp4E8GDx6sd999168Y/a4MdO7cWUeOHNGtt96qYcOG6dy5cxoxYoT27Nmjm266yd/DAQBQ7RiGYdqWmpqq0NBQjy01NbXcOU+ePKnS0lJFRkZ6jEdGRqqwsLDCOAsLC/3a/3Ku6hHGoaGhmjlz5tW8FQAAW0lOTi737b26zbHzOxnYt29fheMOh0PBwcFq2bJltbtIAAD8YWaboKKWQEUaNWqkwMBAFRUVeYwXFRWpSZMmFb6nSZMmfu1/OX4nA927dy97auFPdx3896cY1q1bV6NGjdJLL73EUwwBADWSFXfVDQoKUs+ePbV582YNHz5ckuR2u7V582ZNnjy5wvfExcVp8+bNmjp1atnYpk2bFBcX59e5/Z4zsH79erVt21ZpaWn68ssv9eWXXyotLU3t27fXmjVr9Morr+hvf/ubnnrqKX8PDQCArSUlJWnlypVavXq1Dh48qIkTJ+rcuXOKj4+XJI0bN85jgmFiYqIyMjL04osv6tChQ5ozZ4527dp12eThcvyuDDz77LNavHixBg8eXDbWpUsXNW/eXLNmzdLOnTtVv359/eEPf9ALL7xQ4TEqmln5o1GqOo5Af8MBAMB0Vt05cNSoUTpx4oRmz56twsJCde/eXRkZGWWTBPPz8xUQ8K/v8b1799aaNWv01FNP6cknn1Tbtm317rvvqnPnzn6d12H4WQu57rrrtGfPHnXo0MFj/NChQ4qJidH58+eVl5enTp066YcffqjwGHPmzNHcuXM9xnqF/kJxYf4FX92MLT1vdQim+G3pt1aHYIrakFw2CqxvdQim6OsIszqEa7ZfFf8+q2lWZVX8Ja2mqduodaUev0lYR9OOVfjdQdOOVVn8bhN06NBB8+fPV0lJSdnYxYsXNX/+/LIE4dixY+WWOvy75ORkFRcXe2w3h5r3gwcAAL7zu02wdOlS3XPPPWrevLm6du0qSdq/f79KS0v1wQcfSJJycnL06KOPXvYYFc2srA3f4gAAtYMVEwit5Hcy0Lt3b+Xm5uqNN97QkSNHJEn333+/xowZo5CQEEnS2LFjzY0SAIAqZObSwprAr2Tg4sWL6tChgz744AP97ne/q6yYAABAFfIrGahbt64uXLhQWbEAAFAt2K1N4PcEwkmTJmnBggX68ccfKyMeAAAs5zYM07aawO85A5mZmdq8ebM++ugjdenSRfXrey59euedd0wLDgAAK9itMuB3MhAWFqaRI0dWRiwAAMACficD6enplREHAADVBqsJAACwOdoEPnj77bf11ltvKT8/3+NOhJK0e/duUwIDAABVw+/VBH/6058UHx+vyMhI7dmzR7fccovCw8OVk5Oju+66qzJiBACgStltNYHfycCyZcuUlpamP//5zwoKCtLjjz+uTZs2acqUKSouLq6MGAEAqFKGif/UBH4nA/n5+erdu7ekS08w/P777yVdugXxm2++aW50AACg0vmdDDRp0kSnT5+WJLVs2VI7duyQJOXm5tpuwgUAoHaiTXAFt99+u9577z1JUnx8vKZNm6ZBgwZp1KhRuvfee00PEACAqmYYhmlbTeD3aoKZM2eqWbNmki7dmjg8PFzbtm3TPffcoyFDhpgeIAAAqFx+JwNt2rRRQUGBIiIiJEkPPvigHnzwQZ06dUoREREqLS01PUgAAKpSTZn4Zxa/k4HLlTzOnj2r4ODgaw4IAACr1ZTyvll8TgaSkpIkSQ6HQ7Nnz1a9evXKXistLdUXX3yh7t27mx4gAABVjWTgMvbs2SPp0g9o//79CgoKKnstKChI3bp10/Tp082PEAAAVCqfk4FPPvlE0qUVBIsXL1bDhg0rLSgAAKxkr7qAJMMmLly4YKSkpBgXLlywOpSrVhuuwTBqx3XUhmswDK6jOqkN12AYtec67MZhGPZojJw5c0ahoaEqLi6usVWN2nANUu24jtpwDRLXUZ3UhmuQas912I3fNx0CAAC1C8kAAAA2RzIAAIDN2SYZcDqdSklJkdPptDqUq1YbrkGqHddRG65B4jqqk9pwDVLtuQ67sc0EQgAAUDHbVAYAAEDFSAYAALA5kgEAAGyOZAAAAJurlcmAYRj6zW9+oxtuuEEOh0N79+61OqSrUhuuozZcg1Q7rqM2XIPEdQCVwqLbIFeqDRs2GHXr1jW2bt1qFBQUGJ9++qnxn//5n0ZUVJQhyVi/fr3VIfrE+zqefvppIzY21mjQoIHRuHFjY9iwYcahQ4esDvNneV/Dn/70J6NLly5GSEiIERISYvzHf/yHsWHDBqvDvCLv67h48WLZa6mpqYYkIzEx0boAfeB9DTNnzjR06XksZVv79u2tDvOKKvpv8c9//tN46KGHjBtuuMEIDg42OnfubGRmZlod6s/yvo5mzZqV++8hyXj00UcrPZb+/ftXq/9/q1s8duDzUwtrkqNHjyoqKkq9e/eWdOnxy926ddOECRM0YsQIi6Pznfd1bN26VZMmTdLNN9+sH3/8UU8++aTuvPNO/f3vf1f9+vUtjrZi3tcQHR2t+fPnq23btjIMQ6tXr9awYcO0Z88e/eIXv7A42svzvo6fZGZm6qWXXlLXrl0tisx33tdQp04d/eIXv9DHH39ctk+dOtX/V4L3dXz77bfq06ePBgwYoL/+9a9q3Lixvv76a11//fUWR/rzKvo9VVpaWvb6gQMHNGjQIN1///1WheiXkpISj0fbo4axOhsx2/jx4z2y6htvvNHjddWQysCVrsMwDOP48eOGJOPTTz+t+gB94Ms1GIZhXH/99cbLL79ctcH54XLX8f333xtt27Y1Nm3aVO2/yVR0DSkpKUa3bt2sDs0vFV3HjBkzjFtvvdXq0Pziy9+NxMRE46abbjLcbneVxiLJyM7ONiZMmGBER0cbwcHBRrt27YxFixaVe9+wYcOMP/7xj0ZUVJQRHR1tGIZhbN261ejWrZvhdDqNnj17GuvXrzckGXv27Cl77/79+40hQ4YY9evXNyIiIoxf/epXxokTJy4bT25ubqX+DGAYtS4Z+O6774ynn37aaN68uVFQUGAcP37c4/Wakgxc6ToMwzC+/vprQ5Kxf/9+CyK8sitdw48//mi8+eabRlBQkPHVV19ZFOWVXe46xo0bZ0ydOtUwjOpf1qzoGlJSUox69eoZUVFRRqtWrYwxY8YY33zzjdWh/qyKrqNjx47G1KlTjfvuu89o3Lix0b17dyMtLc3qUH/Wlf5uuFwuIzw83Hj22WerJJa4uDgjISHBKCgoMAoKCowLFy4Ys2fPNjIzM42cnBzj9ddfN+rVq2esW7eu7H3jx483GjRoYIwdO9Y4cOCAceDAAaO4uNi44YYbjF/96lfGV199ZWzYsMFo166dRzLw7bffGo0bNzaSk5ONgwcPGrt37zYGDRpkDBgw4LLx/Pjjj5X+c7C76l8T9FNoaKhCQkIUGBioJk2aWB3OVbvSdbjdbk2dOlV9+vRR586dLYjwyi53Dfv371dcXJwuXLigBg0aaP369erUqZOFkf68iq5j7dq12r17tzIzMy2OzjcVXUOvXr306quvqn379iooKNDcuXPVt29fHThwQCEhIRZHXLGKriMnJ0fLly9XUlKSnnzySWVmZmrKlCkKCgrS+PHjLY64Ylf6+/3uu+/qu+++08MPP1wlsQQFBalevXoescydO7fs31u1aqXt27frrbfe0gMPPFA2Xr9+fb388stl7YEVK1bI4XBo5cqVCg4OVqdOnXTs2DElJCSUvWfJkiWKiYnRvHnzysZWrVqlFi1a6MiRI2rXrl2F8aBy1bpkwC4mTZqkAwcO6PPPP7c6FL+1b99ee/fuVXFxsd5++22NHz9en376abVOCP7dP/7xDyUmJmrTpk0KDg62Opyrdtddd5X9e9euXdWrVy/deOONeuutt/TII49YGJl/3G63YmNjyz5cYmJidODAAa1YsaLaJgNX8sorr+iuu+5S06ZNLYth6dKlWrVqlfLz83X+/HmVlJSoe/fuHvt06dLFY57A4cOH1bVrV4+/F7fccovHe7788kt98sknatCgQblzHj16VO3atTP3QuATkoEaaPLkyfrggw/02WefqXnz5laH47egoCC1adNGktSzZ09lZmZq8eLFeumllyyOzDdZWVk6fvy4evToUTZWWlqqzz77TEuWLJHL5VJgYKCFEV6dsLAwtWvXTtnZ2VaH4peoqKhyiWTHjh31l7/8xaKIrs0333yjjz/+WO+8845lMaxdu1bTp0/Xiy++qLi4OIWEhOj555/XF1984bHf1UxcPnv2rIYOHaoFCxaUey0qKuqqY8a1IRmoQQzD0O9//3utX79eW7ZsUatWrawOyRRut1sul8vqMHx2xx13aP/+/R5j8fHx6tChg2bMmFEjEwHp0i/po0ePauzYsVaH4pc+ffro8OHDHmNHjhzRjTfeaFFE1yY9PV0RERH65S9/WWXnDAoK8ljJsHXrVvXu3VuPPvpo2djRo0eveJz27dvr9ddfl8vlKntqoXcrrUePHvrLX/6i6Ojoy65e8Y4Hla9W3nTI29mzZ7V3796ym3rk5uZq7969ys/PtzYwP02aNEmvv/661qxZo5CQEBUWFqqwsFDnz5+3OjSfJScn67PPPlNeXp7279+v5ORkbdmyRQ899JDVofksJCREnTt39tjq16+v8PDwajt/oyLTp0/Xp59+qry8PG3btk333nuvAgMDNXr0aKtD88u0adO0Y8cOzZs3T9nZ2VqzZo3S0tI0adIkq0Pzm9vtVnp6usaPH1+lyzyjo6P1xRdfKC8vTydPnlTbtm21a9cubdy4UUeOHNGsWbN8mh8zZswYud1u/eY3v9HBgwe1ceNGvfDCC5Ikh8Mh6dLvsdOnT2v06NHKzMzU0aNHtXHjRsXHx5clAN7xuN3uyrt4SLJJMrBr1y7FxMQoJiZGkpSUlKSYmBjNnj3b4sj8s3z5chUXF+u2225TVFRU2bZu3TqrQ/PZ8ePHNW7cOLVv31533HGHMjMztXHjRg0aNMjq0Gznn//8p0aPHq327dvrgQceUHh4uHbs2KHGjRtbHZpfbr75Zq1fv15vvvmmOnfurGeeeUaLFi2qUQnmTz7++GPl5+drwoQJVXre6dOnKzAwUJ06dVLjxo01ePBgjRgxQqNGjVKvXr106tQpjyrB5TRs2FDvv/++9u7dq+7du2vmzJllv2d/mkfQtGlTbd26VaWlpbrzzjvVpUsXTZ06VWFhYQoICKgwnpr2xa0mchiGYVgdBACgdnrjjTcUHx+v4uJiXXfddVaHg8tgzgAAwDSvvfaaWrdurWbNmunLL7/UjBkz9MADD5AIVHMkAwAA0xQWFmr27NkqLCxUVFSU7r//fj377LNWh4UroE0AAIDN2WICIQAAuDySAQAAbI5kAAAAmyMZAADA5kgGAACwOZIBAABsjmQAAACbIxkAAMDm/j8e0hLZOmkjlgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(df.corr())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwHjEhgVMOkk",
        "outputId": "0dff3300-a65e-4c6a-d831-8796c785c8a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.94148548,  0.25092826, -0.05761952, ...,  0.38756454,\n",
              "         0.8235221 , -0.10314457],\n",
              "       [ 0.34669831,  1.15711521,  0.04529666, ..., -0.69463614,\n",
              "        -0.27850747, -0.80181728],\n",
              "       [-1.14026962,  0.5321587 , -3.55676965, ..., -0.69463614,\n",
              "         0.54484796,  1.38454646],\n",
              "       ...,\n",
              "       [ 1.83366624, -0.62401086,  0.8686261 , ..., -0.69463614,\n",
              "         1.72287957,  1.99588508],\n",
              "       [-1.14026962,  0.62590217, -3.55676965, ..., -0.69463614,\n",
              "         1.31753536, -0.80784032],\n",
              "       [-1.14026962,  0.12593696,  1.38320701, ..., -0.69463614,\n",
              "        -1.20319896, -0.63618367]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfDSlxVmMOkk"
      },
      "source": [
        "# Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xlYtZwrMOkk",
        "outputId": "8e164f4a-8907-4f0a-d517-55e2f088b942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ReLU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ReLU()          # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  \n",
        "# optimizer = optim.Adam(params=model.parameters(),lr=0.03)     # setup 1 optimizer adam\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), 'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_iJtlRiNMOkl"
      },
      "source": [
        "# Dropouts  // model1, model2, model3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5l97YxqMOkl",
        "outputId": "d7d460b6-15fa-40cf-a026-b3a27015b796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7500\n",
            "Test Accuracy: 0.7566\n",
            "Test Accuracy: 0.7697\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self,dropout):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(dropout)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ReLU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ReLU()          # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "# model_1 = SimpleBinaryClassifier()\n",
        "# criterion = nn.BCELoss()\n",
        "# optimizer = optim.SGD(model_1.parameters(), lr=0.01)  \n",
        "# optimizer = optim.Adam(params=model.parameters(),lr=0.03)     # setup 1 optimizer adam\n",
        "dropout_rate = [0.1,0.3,0.5]\n",
        "\n",
        "for dropout in dropout_rate:\n",
        "    model_1 = SimpleBinaryClassifier(dropout)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.SGD(model_1.parameters(), lr=0.01)  \n",
        "# Train the model\n",
        "    epochs = 50\n",
        "    for epoch in range(epochs):\n",
        "        model_1.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Forward pass\n",
        "            outputs = model_1(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        # Print training loss at each epoch\n",
        "        # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    with torch.no_grad():\n",
        "        model_1.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in test_loader:\n",
        "            # Forward pass\n",
        "            outputs = model_1(inputs)\n",
        "            predicted_labels = (outputs >= 0.5).int()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted_labels == labels).sum().item()\n",
        "        accuracy = correct / total\n",
        "        print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUYxkLlScxp0"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_1.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2l_vfTfNoMo"
      },
      "source": [
        "# Activation Function - LeakyRelu\n",
        "# Model_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onxwfwWlNDep",
        "outputId": "feb5ef26-de3d-4ce2-80ab-9a356209803f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7763\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.LeakyReLU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.LeakyReLU()         # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_4 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model_4.parameters(), lr=0.01)  \n",
        "# optimizer = optim.Adam(params=model.parameters(),lr=0.03)     # setup 1 optimizer adam\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_4.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_4(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_4.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_4(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "5t-bTeH4c2_f"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_4.state_dict(), r'sungjun_abhinav_assignment2_part2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWp7KAkyOiE4"
      },
      "source": [
        "# Activation Function - Tanh\n",
        "# Model_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P7R-V7_aDZF",
        "outputId": "b2f6fbd7-3ef0-40b1-dc63-03d45a14f743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.Tanh()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.Tanh()         # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_5 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model_5.parameters(), lr=0.01)  \n",
        "# optimizer = optim.Adam(params=model.parameters(),lr=0.03)     # setup 1 optimizer adam\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_5.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_5(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_5.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_5(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z9UE-xNc5Su"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_5.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woq1XY5BaDbs"
      },
      "source": [
        "# Activation Function - ELU\n",
        "# Model_6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCoX5intaDem",
        "outputId": "96767672-1991-4553-e12d-b85d422c9af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_6 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model_6.parameters(), lr=0.01)  \n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_6.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_6(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_6.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_6(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "yMTiS6xOc7ZE"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_6.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I682NkQhdbo2"
      },
      "source": [
        "# Optimizer Adams\n",
        "# Model_7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eRTjFqVdeSl",
        "outputId": "f836d4ad-f007-41dd-e6cd-2e0b0b9a1aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7368\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_7 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_7.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_7.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_7(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_7.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_7(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhPIO2ZedeX6"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_7.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbfQX6ICepkn"
      },
      "source": [
        "# Optimizer - Adagrad\n",
        "# Model_8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVo_3quSeoFO",
        "outputId": "c258731f-d567-4beb-9da0-daacb36de20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7434\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_8 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adagrad(params=model_8.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_8.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_8(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_8.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_8(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "odyvp29qeoIS"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_8.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKLv-HRSf_gG"
      },
      "source": [
        "# Optimizer - RMSPROP\n",
        "# Model_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMNMshvbeoLR",
        "outputId": "b599d170-802d-4dba-e235-10b8fd16e746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7303\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_9 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.RMSprop(params=model_9.parameters(),lr=0.1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_9.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_9(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_9.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_9(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "PhIc1VC2gXg9"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_9.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqCqBHmPgxtu"
      },
      "source": [
        "# Initializer - Kaiming Initialization \n",
        "# Model_10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsqmCK0qgvoF",
        "outputId": "7b762e3e-ee90-46f6-9f72-1093aa7e4403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7566\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.kaiming_normal_(self.input_layer.weight)\n",
        "        nn.init.kaiming_normal_(self.hidden_layer1.weight)\n",
        "        nn.init.kaiming_normal_(self.hidden_layer2.weight)\n",
        "        nn.init.kaiming_normal_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_10 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_10.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_10.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_10(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_10.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_10(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "T_eGqHCvizF6"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_10.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQv_hyfujH2c"
      },
      "source": [
        "# Initializer - weights zeros\n",
        "# Model_11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLCG7eIEjGZs",
        "outputId": "5e557b45-f944-4821-dcd4-08efa5820afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7434\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.zeros_(self.input_layer.weight)\n",
        "        nn.init.zeros_(self.hidden_layer1.weight)\n",
        "        nn.init.zeros_(self.hidden_layer2.weight)\n",
        "        nn.init.zeros_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_11 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_11.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_11.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_11(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_11.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_11(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "GmPnt3jNkuo8"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_11.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XvZD63zk9K1"
      },
      "source": [
        "# Initializer - xavier\n",
        "# Model_12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpXqf0TlkznY",
        "outputId": "2d6bfab8-2430-497b-e3dd-37fa2849643e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7566\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.xavier_uniform_(self.input_layer.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer1.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer2.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_12 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_12.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_12.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_12(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_12.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_12(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "sSErQn6NoD82"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_12.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttw7-pqqo1vJ"
      },
      "source": [
        "# Gradient clipping \n",
        "# Model_13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN_Znlxaq8dA",
        "outputId": "de04d963-5ed9-481c-f435-46fa906c00d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7566\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.xavier_uniform_(self.input_layer.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer1.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer2.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_13 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_13.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_13.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_13(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #gradient clipping \n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_13.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_13(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "Y1YXD4tXr5-V"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_13.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv44vR0wsXSb"
      },
      "source": [
        "# Batch Normalization \n",
        "# Model_14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOsNGtGwr_oO",
        "outputId": "4efd614e-da36-4458-e84b-fc25eaa5c9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7632\n"
          ]
        }
      ],
      "source": [
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.batch1 = nn.BatchNorm1d(128)\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.batch2 = nn.BatchNorm1d(128)\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.batch3 = nn.BatchNorm1d(64)\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.xavier_uniform_(self.input_layer.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer1.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer2.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.batch1(x)\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.batch2(x)\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.batch3(x)\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_14 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_14.parameters(),lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_14.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_14(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #gradient clipping \n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_14.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_14(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "T6p7Ko2ptWPN"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_14.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKH7xCEkuBs8"
      },
      "source": [
        "# Learning rate scheduler\n",
        "# Model_15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnTQqhq-tqaq",
        "outputId": "433a8017-4fbd-44a4-f717-01eb19aba1a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7763\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.xavier_uniform_(self.input_layer.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer1.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer2.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "# https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "model_15 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(params=model_15.parameters(),lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5) #scheduler call\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_15.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_15(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  #gradient clipping \n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        scheduler.step(loss)\n",
        "    \n",
        "    # Print training loss at each epoch\n",
        "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_15.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_15(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "g5AmAMVuvtz-"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_15.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCNwqEyUvxRl"
      },
      "source": [
        "# cyclic Learning rate scheduler\n",
        "# Model_16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubvkWdlPwC8R",
        "outputId": "6746b9f7-7023-4de8-9d4e-e3602dba00e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "class SimpleBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleBinaryClassifier, self).__init__()\n",
        "        self.dropouts = nn.Dropout(0.3)\n",
        "        self.input_layer = nn.Linear(7, 128)   # input layer to hidden layer 1\n",
        "        self.hidden_layer1 = nn.Linear(128, 128)  # hidden layer 1 to hidden layer 2\n",
        "        self.hidden_layer2 = nn.Linear(128, 64)    # hidden layer 2 to hidden layer 3\n",
        "        self.hidden_layer3 = nn.Linear(64,1) # hidden layer 2 to output layer\n",
        "        self.activation1 = nn.ELU()          # activation function for hidden layers   (base setup)\n",
        "        self.activation2 = nn.ELU()        # activation function for hidden layers\n",
        "        self.activation3 = nn.Sigmoid()    # activation function for output layer   (base setup)\n",
        "        # weights initiallization \n",
        "        nn.init.xavier_uniform_(self.input_layer.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer1.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer2.weight)\n",
        "        nn.init.xavier_uniform_(self.hidden_layer3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.activation1(self.input_layer(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer1(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation2(self.hidden_layer2(x))\n",
        "        x = self.dropouts(x)\n",
        "        x = self.activation3(self.hidden_layer3(x))\n",
        "        return x\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train.values.reshape(-1, 1)).float())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test.values.reshape(-1, 1)).float())\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # batch size tune\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "model_16 = SimpleBinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(params=model_16.parameters(),lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1, mode='triangular')\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_16.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_16(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        scheduler.step(loss)\n",
        "    \n",
        "  \n",
        "\n",
        "# Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    model_16.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        # Forward pass\n",
        "        outputs = model_16(inputs)\n",
        "        predicted_labels = (outputs >= 0.5).int()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_labels == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "5Sm9BAUp1QoL"
      },
      "outputs": [],
      "source": [
        "# Save the model weights\n",
        "torch.save(model_16.state_dict(), r'sungjun_abhinav_assignment2_part1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k9PbkeD1USr"
      },
      "source": [
        "# Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ztf9xXHy4Bty",
        "outputId": "2127804f-2ea0-4ce0-c5aa-fc024fdc26da"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "acc_list = [0.7763,0.75,0.7632,0.7566,0.7566,0.7763]\n",
        "names_list = [\"LLR\",\"CRS\",\"Batch Normalization\",\"Gradient Clipping\",\"kaiming initiallization\",\"LeakyRELU\"]\n",
        "\n",
        "sns.barplot(y=names_list,x=acc_list)\n",
        "sns.color_palette(\"pastel\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"Methods\")\n",
        "plt.title(\"Different comparision of methods/models\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
